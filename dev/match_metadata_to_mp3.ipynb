{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "clean-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, gzip, json, pickle, shutil, random\n",
    "\n",
    "from pydub.utils import mediainfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hazardous-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data'\n",
    "#mp3s_path = '%s/mp3s' % data_path\n",
    "mp3_path = 'D:/mp3_dot_com'\n",
    "mp3s_path = '%s/mp3' % mp3_path\n",
    "\n",
    "local_mp3s_path = '%s/mp3s' % data_path\n",
    "\n",
    "#song_data_file = '%s/mp3com_html_analysis_output.txt' % data_path\n",
    "song_data_file_path = '%s/mp3com_html_analysis_output.txt' % mp3_path\n",
    "\n",
    "#create this cleaned metadata file\n",
    "metadata_path = '%s/metadata.json.gz' % data_path\n",
    "\n",
    "genre_counts_path = '%s/genre_cts.pkl' % data_path\n",
    "\n",
    "#for mapping 1000+ unnormalized genres to a few genres\n",
    "genre_map_path = '%s/genre_map.txt' % data_path\n",
    "\n",
    "data={}\n",
    "genre_map={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "broken-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "temporal-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Parse song file - extract and clean select fields\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extraordinary-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metadata_file(song_file_path, metadata_path, genre_counts_path):\n",
    "    #Headers and record example:\n",
    "    #File Name\tArtist Name\tSong Name\tGenre\tComment\tCD\tLabel\tCredits\tDownload Link\tMp3 Filename\n",
    "    #.\\artist_song\\0\\249.html\t Beefchow\tKeep on Dancin (original)\tClub\tDance (Pretty upbeat and catchy)\tTekknotrancemissions\t\tDJ Beefchow\thttp://play.mp3.com/cgi-bin/play/play.cgi/AAIAQvkAAADABG5vcm1QGAAAAFL5AAAAUQEAAABDwienPtGPy4rQmW9N6pQj_gKeqQs-/Keep_on_Dancin_origina.mp3\tKeep_on_Dancin_origina.mp3\n",
    "    data = {}\n",
    "    genre_cts = {}\n",
    "    \n",
    "    #some mp3 filenames are duplicated, the actual filenames have (2) etc after them, but we have to \n",
    "    #match these through their metadata and update the records\n",
    "    data_to_disambiguate = {} #mp3_filename: [recs with this name]\n",
    "    dups = 0\n",
    "    idx=0\n",
    "    \n",
    "    fields = ['mp3_filename', 'genre', 'artist_name', 'album_name', 'song_name', 'comment']\n",
    "    field_cts = {f:0 for f in fields}\n",
    "    \n",
    "    mp3_filenames = set()\n",
    "    \n",
    "    with open(song_file_path, encoding='ISO-8859-1') as f:\n",
    "        headers = f.readline().replace('\\n','')\n",
    "        \n",
    "        #clean up headers\n",
    "        headers = headers.replace('CD', 'album_name')\n",
    "        headers = [h.lower().replace(' ','_') for h in headers.split('\\t')]\n",
    "        \n",
    "        #select only the headers we're interested in\n",
    "        col_idx = [headers.index(field) for field in fields]\n",
    "        \n",
    "        headers = [headers[i] for i in col_idx]\n",
    "        \n",
    "        #lines.append('ID\\t%s' % '\\t'.join(headers))\n",
    "        print(headers, col_idx)\n",
    "\n",
    "        for i,line in enumerate(f):\n",
    "            items = line.replace('\\n','').split('\\t')\n",
    "\n",
    "            if not len(items)==10:\n",
    "                continue\n",
    "                \n",
    "            #no mp3 name\n",
    "            if not items[-1]:\n",
    "                continue\n",
    "\n",
    "            rec = {f:'' for f in fields if not f=='mp3_filename'}\n",
    "            idx+=1\n",
    "            rec['ID'] = idx\n",
    "\n",
    "            items = [items[j].strip() for j in col_idx]\n",
    "\n",
    "            #'mp3_filename', 'genre', 'artist_name', 'album_name', 'song_name', 'comment'\n",
    "            mp3_filename = ''  #use as key for deduping\n",
    "            if items[0]:\n",
    "                field_cts['mp3_filename']+=1\n",
    "                mp3_filename = items[0]\n",
    "            if items[1]:\n",
    "                field_cts['genre']+=1\n",
    "                genre = format_text(items[1])\n",
    "                if genre not in genre_cts:\n",
    "                    genre_cts[genre]=0\n",
    "                genre_cts[genre]+=1\n",
    "                rec['genre'] = genre\n",
    "            if items[2]:\n",
    "                field_cts['artist_name']+=1\n",
    "                rec['artist_name'] = format_text(items[2])\n",
    "            if items[3]:\n",
    "                field_cts['album_name']+=1\n",
    "                rec['album_name'] = items[3]\n",
    "            if items[4]:\n",
    "                field_cts['song_name']+=1\n",
    "                rec['song_name'] = items[4]\n",
    "            if items[5]:\n",
    "                field_cts['comment']+=1\n",
    "                rec['comment'] = items[5]\n",
    "\n",
    "            #a duplicate filename, store in separate dict for disambiguation\n",
    "            if mp3_filename in mp3_filenames:\n",
    "                if mp3_filename not in data_to_disambiguate:\n",
    "                    data_to_disambiguate[mp3_filename] = []\n",
    "                \n",
    "                #if original already stored in data, remove and store in data_to_disambiguate\n",
    "                if mp3_filename in data:\n",
    "                    dup_rec = data[mp3_filename]\n",
    "                    data_to_disambiguate[mp3_filename].append(dup_rec)\n",
    "                    del data[mp3_filename]\n",
    "                    dups+=1\n",
    "                \n",
    "                data_to_disambiguate[mp3_filename].append(rec)\n",
    "                dups+=1\n",
    "            else:\n",
    "                data[mp3_filename] = rec\n",
    "                mp3_filenames.add(mp3_filename)\n",
    "                \n",
    "            if i and i%25000==0:\n",
    "                print(i, dups, rec)\n",
    "        \n",
    "    print('Storing genre counts')\n",
    "    with gzip.open(genre_counts_path, 'wb') as oz:\n",
    "        pickle.dump(genre_cts, oz)\n",
    "        \n",
    "    print('Storing %d unambiguous song records' % len(data))\n",
    "    with gzip.open(metadata_path, 'wt', encoding='utf-8') as oz:\n",
    "        json.dump(data, oz)\n",
    "        \n",
    "    print('\\n\\nTOTAL: %d\\nDUP FILENAMES: %d\\nCOUNTS: %s\\nPERCENT FIELD COVERAGE: %s' % (\n",
    "        idx, dups, field_cts, [(k,v/idx) for k,v in field_cts.items()]))\n",
    "    \n",
    "    return data, data_to_disambiguate, genre_cts\n",
    "            \n",
    "            \n",
    "def format_text(text):\n",
    "    return text.strip().lower().replace(' ', '_').replace('&amp;', '&')\n",
    "\n",
    "\n",
    "def save_metadata(data, metadata_path):\n",
    "    with gzip.open(metadata_path, 'wt', encoding='utf-8') as oz:\n",
    "        json.dump(data, oz)\n",
    "        \n",
    "        \n",
    "def load_metadata(metadata_path):\n",
    "    with gzip.open(metadata_path, 'rt', encoding='utf-8') as fz:\n",
    "        data = json.load(fz)\n",
    "    print('loaded metadata for %d records' % len(data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "express-brake",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded metadata for 445385 records\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(metadata_path):\n",
    "    data, data_to_disambiguate, genre_cts = parse_metadata_file(song_data_file_path, metadata_path)\n",
    "    print(len(data), len(data_to_disambiguate), sum([len(v) for v in data_to_disambiguate.values()]))\n",
    "    #397801 40334 174445\n",
    "else:\n",
    "    data = load_metadata(metadata_path)\n",
    "    with gzip.open(genre_counts_path, 'rb') as fz:\n",
    "        genre_cts = pickle.load(fz)\n",
    "    print(len(genre_cts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "combined-minister",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genre_cts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bridal-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disambiguate_dup_filenames(data, data_to_disambiguate, mp3s_path, metadata_path):\n",
    "    found = []\n",
    "    missing=[]\n",
    "    no_metadata = 0\n",
    "    for i, fn in enumerate(data_to_disambiguate.keys()):\n",
    "        if i%1000==0:\n",
    "            print('%d - found: %d, missing: %d, no meta: %d, recs: %d' % (\n",
    "                i, len(found), len(missing), no_metadata, len(data)))\n",
    "            with gzip.open(metadata_path, 'wt', encoding='utf-8') as oz:\n",
    "                json.dump(data, oz)\n",
    "            \n",
    "        #shouldn't happen\n",
    "        if fn in data:\n",
    "            continue\n",
    "            \n",
    "        fp = '%s/%s' % (mp3s_path, fn)\n",
    "        if not os.path.exists(fp):\n",
    "            missing.append(fn)\n",
    "            continue\n",
    "            \n",
    "        dup_recs = data_to_disambiguate[fn]\n",
    "        \n",
    "        #metadata = {'encoder': 'LAME3.92 ', 'title': 'Believe', 'artist': 'DREAMTRONIX', \n",
    "        #            'comment': 'http://www.mp3.com/DREAMTRONIX','genre': 'Blues'}\n",
    "        metadata = mediainfo(fp).get('TAG', None)\n",
    "        if metadata==None:\n",
    "            no_metadata+=1\n",
    "            continue\n",
    "            \n",
    "        artist = format_text(metadata['artist']) if 'artist' in metadata else ''\n",
    "        genre = format_text(metadata['genre']) if 'genre' in metadata else ''\n",
    "        \n",
    "        for dup_rec in dup_recs:\n",
    "            if dup_rec['artist_name']==artist:\n",
    "                data[fn] = dup_rec\n",
    "                found.append(fn)\n",
    "                break\n",
    "                \n",
    "    with gzip.open(metadata_path, 'wt', encoding='utf-8') as oz:\n",
    "        json.dump(data, oz)\n",
    "                \n",
    "    print('Found: %d\\tMissing: %d\\tNo Metadata: %d\\tTotal Recs: %d' % (len(found), len(missing), no_metadata, len(data)))\n",
    "    \n",
    "    return data, found, missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "animated-mention",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - found: 0, missing: 0, no meta: 0, recs: 440115\n",
      "1000 - found: 0, missing: 44, no meta: 44, recs: 440115\n",
      "2000 - found: 0, missing: 99, no meta: 84, recs: 440115\n",
      "3000 - found: 0, missing: 169, no meta: 120, recs: 440115\n",
      "4000 - found: 343, missing: 241, no meta: 162, recs: 440458\n",
      "5000 - found: 880, missing: 312, no meta: 193, recs: 440995\n",
      "6000 - found: 1380, missing: 403, no meta: 221, recs: 441495\n",
      "7000 - found: 1890, missing: 480, no meta: 257, recs: 442005\n",
      "8000 - found: 2381, missing: 590, no meta: 290, recs: 442496\n",
      "9000 - found: 2849, missing: 724, no meta: 315, recs: 442964\n",
      "10000 - found: 3329, missing: 842, no meta: 345, recs: 443444\n",
      "11000 - found: 3792, missing: 965, no meta: 366, recs: 443907\n",
      "12000 - found: 4193, missing: 1108, no meta: 388, recs: 444308\n",
      "13000 - found: 4621, missing: 1246, no meta: 407, recs: 444736\n",
      "14000 - found: 5031, missing: 1394, no meta: 435, recs: 445146\n",
      "15000 - found: 5426, missing: 1548, no meta: 453, recs: 445541\n",
      "16000 - found: 5828, missing: 1703, no meta: 481, recs: 445943\n",
      "17000 - found: 6230, missing: 1869, no meta: 502, recs: 446345\n",
      "18000 - found: 6610, missing: 2040, no meta: 521, recs: 446725\n",
      "19000 - found: 6995, missing: 2192, no meta: 546, recs: 447110\n",
      "20000 - found: 7369, missing: 2371, no meta: 563, recs: 447484\n",
      "21000 - found: 7717, missing: 2553, no meta: 575, recs: 447832\n",
      "22000 - found: 8067, missing: 2731, no meta: 595, recs: 448182\n",
      "23000 - found: 8422, missing: 2932, no meta: 612, recs: 448537\n",
      "24000 - found: 8758, missing: 3126, no meta: 630, recs: 448873\n",
      "25000 - found: 9125, missing: 3301, no meta: 643, recs: 449240\n",
      "26000 - found: 9445, missing: 3500, no meta: 663, recs: 449560\n",
      "27000 - found: 9779, missing: 3688, no meta: 682, recs: 449894\n",
      "28000 - found: 10103, missing: 3890, no meta: 699, recs: 450218\n",
      "29000 - found: 10423, missing: 4092, no meta: 722, recs: 450538\n",
      "30000 - found: 10749, missing: 4305, no meta: 737, recs: 450864\n",
      "31000 - found: 11065, missing: 4523, no meta: 754, recs: 451180\n",
      "32000 - found: 11369, missing: 4739, no meta: 766, recs: 451484\n",
      "33000 - found: 11677, missing: 4974, no meta: 786, recs: 451792\n",
      "34000 - found: 11967, missing: 5212, no meta: 809, recs: 452082\n",
      "35000 - found: 12273, missing: 5461, no meta: 826, recs: 452388\n",
      "36000 - found: 12579, missing: 5695, no meta: 840, recs: 452694\n",
      "37000 - found: 12857, missing: 5925, no meta: 863, recs: 452972\n",
      "38000 - found: 13173, missing: 6169, no meta: 884, recs: 453288\n",
      "39000 - found: 13446, missing: 6422, no meta: 903, recs: 453561\n",
      "40000 - found: 13715, missing: 6667, no meta: 917, recs: 453830\n",
      "Found: 13799\tMissing: 6752\tNo Metadata: 925\n"
     ]
    }
   ],
   "source": [
    "# Try deduping ambiguous records by extracting metadata from unmatched files\n",
    "if not os.path.exists(metadata_path):\n",
    "    data, found, missing = disambiguate_dup_filenames(data, data_to_disambiguate, mp3s_path, metadata_path)\n",
    "    len(data) #453830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "respective-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disambiguate_numbered_files(data, data_to_disambiguate, mp3s_path, metadata_path):\n",
    "    no_metadata = 0\n",
    "    found = []\n",
    "    checked=0\n",
    "    \n",
    "    #find files with (number) at the end, remove the number and try to match in dup data\n",
    "    for fn in os.listdir(mp3s_path):\n",
    "        if not fn.endswith('mp3'):\n",
    "            continue\n",
    "            \n",
    "        #shouldn't happen\n",
    "        if fn in data:\n",
    "            continue\n",
    "        \n",
    "        if not re.match('.+ \\([0-9]+\\)\\.mp3', fn):\n",
    "            continue\n",
    "            \n",
    "        file_name = re.sub(' \\([0-9]+\\)\\.mp3', '.mp3', fn)\n",
    "        \n",
    "        if not file_name in data_to_disambiguate:\n",
    "            continue\n",
    "        \n",
    "        checked+=1\n",
    "        \n",
    "        if checked%1000==0:\n",
    "            print(len(found), no_metadata)\n",
    "            \n",
    "        fp = '%s/%s' % (mp3s_path, fn)\n",
    "        \n",
    "        metadata = mediainfo(fp).get('TAG', None)\n",
    "        if metadata==None:\n",
    "            no_metadata+=1\n",
    "            continue\n",
    "            \n",
    "        artist = format_text(metadata['artist']) if 'artist' in metadata else ''\n",
    "        \n",
    "        dup_recs = data_to_disambiguate[file_name]\n",
    "        \n",
    "        for dup_rec in dup_recs:\n",
    "            if dup_rec['artist_name']==artist:\n",
    "                data[fn] = dup_rec\n",
    "                found.append(fn)\n",
    "                \n",
    "                #this is slow so store periodically\n",
    "                if len(found)%1000==0:\n",
    "                    print('Storing %d records' % len(data))\n",
    "                    with gzip.open(metadata_path, 'wt', encoding='utf-8') as oz:\n",
    "                        json.dump(data, oz)\n",
    "                break\n",
    "                \n",
    "    with gzip.open(metadata_path, 'wt', encoding='utf-8') as oz:\n",
    "        json.dump(data, oz)    \n",
    "        \n",
    "    print('Found: %d\\tNo metadata: %d\\tTotal Recs: %d' % (len(found), no_metadata, len(data)))\n",
    "    \n",
    "    return data, found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "interim-racing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "917 13\n",
      "Storing 398801 records\n",
      "1827 29\n",
      "Storing 399801 records\n",
      "2757 40\n",
      "Storing 400801 records\n",
      "3671 53\n",
      "Storing 401801 records\n",
      "4584 67\n",
      "Storing 402801 records\n",
      "5506 79\n",
      "Storing 403801 records\n",
      "6415 93\n",
      "Storing 404801 records\n",
      "7302 114\n",
      "Storing 405801 records\n",
      "8228 125\n",
      "Storing 406801 records\n",
      "9155 137\n",
      "Storing 407801 records\n",
      "10086 147\n",
      "10993 170\n",
      "Storing 408801 records\n",
      "11929 177\n",
      "Storing 409801 records\n",
      "12848 198\n",
      "Storing 410801 records\n",
      "13773 215\n",
      "Storing 411801 records\n",
      "14683 233\n",
      "Storing 412801 records\n",
      "15599 249\n",
      "Storing 413801 records\n",
      "16524 265\n",
      "Storing 414801 records\n",
      "17431 283\n",
      "Storing 415801 records\n",
      "18333 304\n",
      "Storing 416801 records\n",
      "19249 317\n",
      "Storing 417801 records\n",
      "20168 330\n",
      "Storing 418801 records\n",
      "21089 344\n",
      "21988 363\n",
      "Storing 419801 records\n",
      "22904 381\n",
      "Storing 420801 records\n",
      "23829 393\n",
      "Storing 421801 records\n",
      "24757 408\n",
      "Storing 422801 records\n",
      "25660 421\n",
      "Storing 423801 records\n",
      "26584 436\n",
      "Storing 424801 records\n",
      "27499 455\n",
      "Storing 425801 records\n",
      "28426 469\n",
      "Storing 426801 records\n",
      "29352 477\n",
      "Storing 427801 records\n",
      "30265 492\n",
      "Storing 428801 records\n",
      "31184 512\n",
      "Storing 429801 records\n",
      "32111 524\n",
      "Storing 430801 records\n",
      "33011 539\n",
      "33926 554\n",
      "Storing 431801 records\n",
      "34833 573\n",
      "Storing 432801 records\n",
      "35757 587\n",
      "Storing 433801 records\n",
      "36653 609\n",
      "Storing 434801 records\n",
      "37574 619\n",
      "Storing 435801 records\n",
      "38496 633\n",
      "Storing 436801 records\n",
      "39416 645\n",
      "Storing 437801 records\n",
      "40333 659\n",
      "Storing 438801 records\n",
      "41259 669\n",
      "Storing 439801 records\n",
      "42180 685\n",
      "Storing 440801 records\n",
      "43102 696\n",
      "Storing 441801 records\n",
      "44016 711\n",
      "44913 728\n",
      "Storing 442801 records\n",
      "45836 740\n",
      "Storing 443801 records\n",
      "46754 755\n",
      "Storing 444801 records\n",
      "Found: 47584\tNo metadata: 769\tTotal Recs: 445385\n"
     ]
    }
   ],
   "source": [
    "#if there were duplicates of a song name then the mp3 had (number) added to the end\n",
    "#locate these and update the filename in the data dict\n",
    "\n",
    "if not os.path.exists(metadata_path):\n",
    "    data, found = disambiguate_numbered_files(data, data_to_disambiguate, mp3s_path, metadata_path)\n",
    "    len(data) #445385"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "correct-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_size_to_data(data, mp3s_path, metadata_path):\n",
    "    ttl = 0\n",
    "    not_found = []\n",
    "    over_5mb = 0\n",
    "    \n",
    "    for i, fn in enumerate(data.keys()):\n",
    "        if i and i%10000==0:\n",
    "            print('Records checked so far: %d\\tRecs found: %d\\t> 5 Mb: %d\\tNot Found: %d, including %s' % (\n",
    "                i, ttl, over_5mb, len(not_found), not_found[-1]))\n",
    "            with gzip.open(metadata_path, 'wt', encoding='utf-8') as oz:\n",
    "                json.dump(data, oz)\n",
    "                \n",
    "        fp = '%s/%s' % (mp3s_path, fn)\n",
    "        if not os.path.exists(fp):\n",
    "            not_found.append(fn)\n",
    "            continue\n",
    "            \n",
    "        ttl+=1\n",
    "            \n",
    "        data[fn]['size_mb'] = os.path.getsize(fp)/1024**2\n",
    "        if data[fn]['size_mb'] > 5:\n",
    "            over_5mb+=1\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "particular-technical",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records checked so far: 10000\tRecs found: 4631\t> 5 Mb: 743\tNot Found: 5369, including Representando.mp3\n",
      "Records checked so far: 20000\tRecs found: 9254\t> 5 Mb: 1476\tNot Found: 10746, including Van_y_vienen.mp3\n",
      "Records checked so far: 30000\tRecs found: 13862\t> 5 Mb: 2293\tNot Found: 16138, including Stay_dot_calm.mp3\n",
      "Records checked so far: 40000\tRecs found: 18431\t> 5 Mb: 3085\tNot Found: 21569, including How_It_Used_To_Be.mp3\n",
      "Records checked so far: 50000\tRecs found: 22951\t> 5 Mb: 3820\tNot Found: 27049, including Peacefull_Summit.mp3\n",
      "Records checked so far: 60000\tRecs found: 27471\t> 5 Mb: 4539\tNot Found: 32529, including Resa_Tunnel_Vision_Rem.mp3\n",
      "Records checked so far: 70000\tRecs found: 32024\t> 5 Mb: 5247\tNot Found: 37976, including Dont_put_a_Spell_on_Me.mp3\n",
      "Records checked so far: 80000\tRecs found: 36557\t> 5 Mb: 6037\tNot Found: 43443, including Southern_Rag_Medley_II.mp3\n",
      "Records checked so far: 90000\tRecs found: 41062\t> 5 Mb: 6750\tNot Found: 48938, including El_Negrito_Del_Batey.mp3\n",
      "Records checked so far: 100000\tRecs found: 45631\t> 5 Mb: 7515\tNot Found: 54369, including ET_Droan_Home_Remix.mp3\n",
      "Records checked so far: 110000\tRecs found: 50253\t> 5 Mb: 8258\tNot Found: 59747, including Her_Dying_Love_broken_.mp3\n",
      "Records checked so far: 120000\tRecs found: 54858\t> 5 Mb: 8968\tNot Found: 65142, including Exhausting.mp3\n",
      "Records checked so far: 130000\tRecs found: 59476\t> 5 Mb: 9680\tNot Found: 70524, including NOT_GETTING_OFF.mp3\n",
      "Records checked so far: 140000\tRecs found: 64122\t> 5 Mb: 10419\tNot Found: 75878, including Green_Snow.mp3\n",
      "Records checked so far: 150000\tRecs found: 68707\t> 5 Mb: 11117\tNot Found: 81293, including Supermodel_Freak.mp3\n",
      "Records checked so far: 160000\tRecs found: 73321\t> 5 Mb: 11792\tNot Found: 86679, including Zeitgeist_Jam.mp3\n",
      "Records checked so far: 170000\tRecs found: 77928\t> 5 Mb: 12494\tNot Found: 92072, including NO_CLIP_IS_FULL_ENOUGH.mp3\n",
      "Records checked so far: 180000\tRecs found: 82562\t> 5 Mb: 13183\tNot Found: 97438, including Arlie.mp3\n",
      "Records checked so far: 190000\tRecs found: 87175\t> 5 Mb: 13892\tNot Found: 102825, including Check_That_Line.mp3\n",
      "Records checked so far: 200000\tRecs found: 91781\t> 5 Mb: 14664\tNot Found: 108219, including drop_in.mp3\n",
      "Records checked so far: 210000\tRecs found: 96319\t> 5 Mb: 15375\tNot Found: 113681, including Vapour_Trails.mp3\n",
      "Records checked so far: 220000\tRecs found: 100958\t> 5 Mb: 16118\tNot Found: 119042, including Computer_Song_5.mp3\n",
      "Records checked so far: 230000\tRecs found: 105602\t> 5 Mb: 16852\tNot Found: 124398, including Defined.mp3\n",
      "Records checked so far: 240000\tRecs found: 110155\t> 5 Mb: 17524\tNot Found: 129845, including Great_American_Novel.mp3\n",
      "Records checked so far: 250000\tRecs found: 114758\t> 5 Mb: 18152\tNot Found: 135242, including The_Ryde.mp3\n",
      "Records checked so far: 260000\tRecs found: 119454\t> 5 Mb: 18838\tNot Found: 140546, including FRIO_ESPACIO.mp3\n",
      "Records checked so far: 270000\tRecs found: 124120\t> 5 Mb: 19483\tNot Found: 145880, including Whats_it_all_about_In_.mp3\n",
      "Records checked so far: 280000\tRecs found: 128672\t> 5 Mb: 20123\tNot Found: 151328, including 0047_etud.mp3\n",
      "Records checked so far: 290000\tRecs found: 133372\t> 5 Mb: 20794\tNot Found: 156628, including Swiss_Banger_copy.mp3\n",
      "Records checked so far: 300000\tRecs found: 137763\t> 5 Mb: 21391\tNot Found: 162237, including Silly_Fool.mp3\n",
      "Records checked so far: 310000\tRecs found: 142113\t> 5 Mb: 21970\tNot Found: 167887, including Scratched_In_The_Stree.mp3\n",
      "Records checked so far: 320000\tRecs found: 146665\t> 5 Mb: 22615\tNot Found: 173335, including Lost_tunnel.mp3\n",
      "Records checked so far: 330000\tRecs found: 151205\t> 5 Mb: 23291\tNot Found: 178795, including dont_eat_my_liver.mp3\n",
      "Records checked so far: 340000\tRecs found: 155848\t> 5 Mb: 23957\tNot Found: 184152, including Mac_Piece_9_of_9.mp3\n",
      "Records checked so far: 350000\tRecs found: 160355\t> 5 Mb: 24626\tNot Found: 189645, including Baby_Tender.mp3\n",
      "Records checked so far: 360000\tRecs found: 164918\t> 5 Mb: 25322\tNot Found: 195082, including Simple_10.mp3\n",
      "Records checked so far: 370000\tRecs found: 169450\t> 5 Mb: 25990\tNot Found: 200550, including Destruction_PT_II.mp3\n",
      "Records checked so far: 380000\tRecs found: 174041\t> 5 Mb: 26747\tNot Found: 205959, including Stump_Huffing.mp3\n",
      "Records checked so far: 390000\tRecs found: 178598\t> 5 Mb: 27486\tNot Found: 211402, including Gravesong.mp3\n",
      "Records checked so far: 400000\tRecs found: 184430\t> 5 Mb: 28368\tNot Found: 215570, including Frammenti_di_Silenzio.mp3\n",
      "Records checked so far: 410000\tRecs found: 194430\t> 5 Mb: 29740\tNot Found: 215570, including Frammenti_di_Silenzio.mp3\n",
      "Records checked so far: 420000\tRecs found: 204430\t> 5 Mb: 30964\tNot Found: 215570, including Frammenti_di_Silenzio.mp3\n",
      "Records checked so far: 430000\tRecs found: 214430\t> 5 Mb: 32273\tNot Found: 215570, including Frammenti_di_Silenzio.mp3\n",
      "Records checked so far: 440000\tRecs found: 224430\t> 5 Mb: 33570\tNot Found: 215570, including Frammenti_di_Silenzio.mp3\n"
     ]
    }
   ],
   "source": [
    "data = add_size_to_data(data, mp3s_path, metadata_path)\n",
    "#224430 or so found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Clean up some obviously wrong genres\n",
    "#\n",
    "# Map all 1000+ genres to normalized set of genres.\n",
    "# Extract metadata from files and store this info also in metadata.json. Provides artist name and genre.\n",
    "# If both genres are the same, then there is more evidence that the assignment is correct.\n",
    "# Maybe look for other sources of evidence, music lists that include genre.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hollow-genre",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_genre_map(genre_map_path):\n",
    "    genre_map ={}\n",
    "    with open(genre_map_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if not line:\n",
    "                continue\n",
    "            g,gm = line.replace('\\n','').split('\\t')\n",
    "            genre_map[g]=gm\n",
    "            \n",
    "    return genre_map\n",
    "\n",
    "\n",
    "def write_genre_map(genre_map, genre_map_path):\n",
    "    with open(genre_map_path, 'w') as o:\n",
    "        for g in sorted(genre_map, key=genre_map.get):\n",
    "            o.write('%s\\t%s\\n' % (g, genre_map[g]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "directed-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(genre_map_path):\n",
    "    genre_map = read_genre_map(genre_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "corporate-setting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock\t\t44037\n",
      "alternative_general\t\t31863\n",
      "pop\t\t17196\n",
      "punk\t\t16677\n",
      "indie\t\t14862\n",
      "electronica\t\t11363\n",
      "experimental\t\t11299\n",
      "hip_hop\t\t11049\n",
      "experimental/post_rock\t\t11035\n",
      "acoustic\t\t10133\n",
      "techno\t\t9926\n",
      "ambient\t\t9293\n",
      "trance\t\t7785\n",
      "alternative_metal\t\t7574\n",
      "heavy_metal\t\t7531\n",
      "emo\t\t7028\n",
      "beats\t\t6787\n",
      "pop_punk\t\t6742\n",
      "folk\t\t6532\n",
      "indie_pop/lo_fi\t\t6531\n",
      "metalcore\t\t6242\n",
      "industrial_electronic\t\t6241\n",
      "dance\t\t6206\n",
      "drum_n'_bass\t\t5973\n",
      "power_pop\t\t5740\n",
      "hardcore_punk\t\t5393\n",
      "aaa/adult_alternative\t\t5020\n",
      "melodic_trance\t\t4950\n",
      "breakbeat/breaks\t\t4362\n",
      "rap\t\t4323\n",
      "guitar_rock\t\t4264\n",
      "new_age\t\t4035\n",
      "instrumental_rock\t\t3889\n",
      "general_comedy\t\t3796\n",
      "death_metal\t\t3733\n",
      "house\t\t3498\n",
      "alternative_hip_hop\t\t3378\n",
      "folk_rock\t\t3227\n",
      "blues_rock\t\t3226\n",
      "down_tempo\t\t3156\n",
      "mood_music\t\t3149\n",
      "film_music\t\t3135\n",
      "progressive_rock\t\t3092\n",
      "jazz_fusion\t\t3062\n",
      "ska\t\t3044\n",
      "new_country\t\t2933\n",
      "country_general\t\t2910\n",
      "piano\t\t2868\n",
      "progressive_trance\t\t2862\n",
      "love_songs\t\t2857\n",
      "general_jazz\t\t2843\n",
      "world_fusion\t\t2838\n",
      "noise\t\t2812\n",
      "alternative_country\t\t2673\n",
      "psychedelic\t\t2668\n",
      "groove\t\t2650\n",
      "industrial\t\t2643\n",
      "trip_hop\t\t2551\n",
      "progressive_electronica\t\t2471\n",
      "pop_vocals\t\t2467\n",
      "smooth_jazz\t\t2463\n",
      "black_metal\t\t2448\n",
      "soft_rock\t\t2437\n",
      "funk\t\t2372\n",
      "abstract\t\t2233\n",
      "grunge\t\t2229\n",
      "post_hardcore\t\t2213\n",
      "progressive_metal\t\t2206\n",
      "rhythm_&_blues\t\t2178\n",
      "classic_rock\t\t2174\n",
      "grindcore\t\t2076\n",
      "christian_rock\t\t2067\n",
      "adult_contemporary\t\t2041\n",
      "club\t\t2017\n",
      "east_coast\t\t1986\n",
      "hard_trance\t\t1965\n",
      "acid_jazz\t\t1931\n",
      "dirty_south\t\t1892\n",
      "garage\t\t1875\n",
      "intelligent_techno\t\t1837\n",
      "new_wave\t\t1764\n",
      "game_soundtracks\t\t1754\n",
      "thrash/speed_metal\t\t1739\n",
      "instrumental_metal\t\t1735\n",
      "industrial_metal\t\t1700\n",
      "contemporary_urban\t\t1697\n",
      "acoustic_blues\t\t1665\n",
      "symphonic_electronica\t\t1660\n",
      "americana\t\t1624\n",
      "leftfield\t\t1620\n",
      "christian_easy_listening\t\t1598\n",
      "skate_punk\t\t1554\n",
      "minimal\t\t1548\n",
      "general_children's_music\t\t1533\n",
      "doom/stoner_metal\t\t1530\n",
      "electric_blues\t\t1512\n",
      "goth\t\t1476\n",
      "classical_general\t\t1474\n",
      "celtic\t\t1435\n",
      "reggae\t\t1427\n",
      "contemporary\t\t1408\n",
      "nu-metal\t\t1408\n",
      "power_metal\t\t1401\n",
      "darkwave\t\t1348\n",
      "euro_dance\t\t1344\n",
      "guitar\t\t1315\n",
      "psytrance\t\t1311\n",
      "brit_pop\t\t1306\n",
      "ambient_drum_n'_bass\t\t1266\n",
      "west_coast\t\t1249\n",
      "detroit\t\t1246\n",
      "industrial_rock\t\t1245\n",
      "general_blues\t\t1245\n",
      "spiritual_easy_listening\t\t1237\n",
      "acid\t\t1234\n",
      "deep_house\t\t1211\n",
      "christian_pop\t\t1205\n",
      "tech_step\t\t1200\n",
      "soul\t\t1181\n",
      "spoken_word\t\t1128\n",
      "electronic_classical\t\t1118\n",
      "big_beat\t\t1118\n",
      "hard_house\t\t1097\n",
      "funky_breaks\t\t1076\n",
      "goa\t\t1069\n",
      "freestyles\t\t1051\n",
      "goth_rock\t\t1034\n",
      "europop\t\t1023\n",
      "dark_ambient/noise\t\t999\n",
      "rapcore\t\t974\n",
      "rock_en_espanol\t\t964\n",
      "gospel\t\t958\n",
      "gothic_metal\t\t950\n",
      "poetry\t\t931\n",
      "gabber\t\t922\n",
      "surf_rock\t\t915\n",
      "pop_and_rock_cover_songs\t\t907\n",
      "baroque\t\t906\n",
      "shoegazer\t\t905\n",
      "experimental_classical\t\t901\n",
      "folk_punk\t\t855\n",
      "lounge\t\t848\n",
      "jazz_vocals\t\t829\n",
      "chamber_music\t\t818\n",
      "bluegrass\t\t815\n",
      "satire\t\t796\n",
      "rave/old_skool\t\t795\n",
      "country_blues\t\t794\n",
      "seasonal/holiday\t\t784\n",
      "jungle\t\t783\n",
      "new_school\t\t780\n",
      "world_traditions\t\t765\n",
      "rockabilly\t\t756\n",
      "idm\t\t737\n",
      "traditional_country\t\t737\n",
      "spiritual_rock\t\t725\n",
      "general_latin\t\t705\n",
      "christmas\t\t646\n",
      "illbient\t\t641\n",
      "horrorcore\t\t628\n",
      "blues_vocals\t\t615\n",
      "spiritual\t\t615\n",
      "symphonic\t\t609\n",
      "spiritual_pop\t\t607\n",
      "happy_hardcore\t\t607\n",
      "dub\t\t605\n",
      "progressive_house\t\t601\n",
      "christian_country\t\t590\n",
      "latin_jazz\t\t589\n",
      "christian_rap\t\t552\n",
      "electro\t\t551\n",
      "old_school\t\t545\n",
      "spiritual_country\t\t539\n",
      "solo_instruments\t\t533\n",
      "vocal_house\t\t531\n",
      "glam\t\t524\n",
      "romantic\t\t517\n",
      "swing/big_band\t\t516\n",
      "alternative_cover_songs\t\t503\n",
      "traditional_jazz\t\t501\n",
      "spiritual_rap\t\t494\n",
      "crooners/vocals\t\t494\n",
      "southern_rock\t\t494\n",
      "interviews\t\t486\n",
      "pop/balada\t\t485\n",
      "opera\t\t473\n",
      "surf_punk\t\t422\n",
      "hardcore_rap\t\t416\n",
      "hard_dance\t\t412\n",
      "jump-up\t\t393\n",
      "mod\t\t386\n",
      "vocals\t\t385\n",
      "dub_reggae\t\t382\n",
      "strings\t\t365\n",
      "j-pop\t\t350\n",
      "bossa_nova\t\t347\n",
      "musicals/broadway\t\t340\n",
      "spiritual_children's\t\t338\n",
      "choral\t\t337\n",
      "political_humor\t\t324\n",
      "indian\t\t323\n",
      "christian_metal\t\t321\n",
      "standards\t\t321\n",
      "bebop\t\t314\n",
      "filtered/disco_house\t\t310\n",
      "dancehall_reggae\t\t306\n",
      "new_grass\t\t300\n",
      "jump_blues\t\t299\n",
      "woodwinds\t\t289\n",
      "easy_listening_cover_songs\t\t285\n",
      "roots_reggae\t\t283\n",
      "country_cover_songs\t\t281\n",
      "western_swing\t\t276\n",
      "crossover\t\t271\n",
      "minimalist\t\t271\n",
      "blues_cover_songs\t\t271\n",
      "native_american\t\t268\n",
      "spiritual_metal\t\t268\n",
      "medieval\t\t267\n",
      "tropical\t\t262\n",
      "christian_blues\t\t253\n",
      "parodies\t\t252\n",
      "salsa\t\t246\n",
      "african\t\t240\n",
      "audio_books\t\t228\n",
      "brazilian\t\t227\n",
      "electronic_cover_songs\t\t227\n",
      "jewish/israeli\t\t224\n",
      "spiritual_blues\t\t219\n",
      "tribal\t\t216\n",
      "french\t\t213\n",
      "arabic\t\t203\n",
      "bass\t\t197\n",
      "oldies\t\t190\n",
      "renaissance\t\t189\n",
      "metal_cover_songs\t\t181\n",
      "percussion\t\t176\n",
      "stories_and_myths\t\t169\n",
      "world/folk_cover_songs\t\t164\n",
      "russian\t\t154\n",
      "south/central_american\t\t154\n",
      "latin_house\t\t151\n",
      "caribbean\t\t149\n",
      "self-help\t\t148\n",
      "15_seconds_or_less\t\t147\n",
      "cuban\t\t131\n",
      "rock-n-roll_oldies\t\t126\n",
      "traditional\t\t120\n",
      "sound_effects\t\t118\n",
      "european\t\t117\n",
      "nouveau_flamenco\t\t114\n",
      "asian\t\t111\n",
      "merengue\t\t111\n",
      "quebecois\t\t108\n",
      "humor\t\t107\n",
      "scandinavian\t\t103\n",
      "two_step\t\t89\n",
      "ranchero\t\t88\n",
      "politics\t\t85\n",
      "middle_eastern/north_african\t\t85\n",
      "urban/r&b_cover_songs\t\t83\n",
      "spanish\t\t79\n",
      "ensembles\t\t78\n",
      "uk_garage\t\t78\n",
      "speak_your_mind\t\t70\n",
      "steel_drums\t\t69\n",
      "north_american\t\t68\n",
      "other_holidays\t\t68\n",
      "paranormal\t\t68\n",
      "german\t\t66\n",
      "chinese\t\t64\n",
      "polka\t\t62\n",
      "tex/mex\t\t61\n",
      "latin_cover_songs\t\t61\n",
      "aliens\t\t57\n",
      "adult_section_(18_&_over)\t\t56\n",
      "bodily_functions\t\t55\n",
      "doo-wop\t\t54\n",
      "shout_outs\t\t53\n",
      "zydeco\t\t50\n",
      "witchcraft\t\t49\n",
      "regional_mexicado\t\t47\n",
      "horror_stories\t\t46\n",
      "u.s.\t\t46\n",
      "film_music_covers\t\t46\n",
      "commercials\t\t43\n",
      "mental_health\t\t42\n",
      "bolero\t\t40\n",
      "hawaiian\t\t39\n",
      "italian\t\t38\n",
      "oceanic\t\t37\n",
      "mariachi\t\t37\n",
      "spoofs\t\t37\n",
      "children's_cover_songs\t\t36\n",
      "tejano\t\t34\n",
      "hip_hop_cover_songs\t\t34\n",
      "recorded_greetings\t\t33\n",
      "mambo\t\t33\n",
      "lies\t\t32\n",
      "movies\t\t32\n",
      "traditional_drumming\t\t32\n",
      "indonesian\t\t28\n",
      "opinions\t\t27\n",
      "education\t\t26\n",
      "music\t\t25\n",
      "emergency!\t\t25\n",
      "nonfiction\t\t24\n",
      "hypnosis\t\t24\n",
      "advice\t\t23\n",
      "japanese\t\t23\n",
      "radio\t\t22\n",
      "time_capsule_recordings\t\t21\n",
      "dumb_stories\t\t21\n",
      "love\t\t20\n",
      "breaking_news\t\t19\n",
      "arts_&_entertainment\t\t19\n",
      "folklore\t\t18\n",
      "bloopers\t\t18\n",
      "tragedies\t\t18\n",
      "illnesses\t\t17\n",
      "hanukkah\t\t17\n",
      "breakups\t\t16\n",
      "announcements\t\t16\n",
      "911\t\t15\n",
      "family\t\t14\n",
      "confessions\t\t14\n",
      "history\t\t14\n",
      "metal\t\t14\n",
      "world\t\t13\n",
      "dating\t\t13\n",
      "sightings\t\t13\n",
      "insults\t\t12\n",
      "baby_talk\t\t11\n",
      "business\t\t11\n",
      "missing_persons\t\t11\n",
      "black_box_recordings\t\t11\n",
      "tv\t\t10\n",
      "urban_legends\t\t10\n",
      "entertainment_reviews\t\t10\n",
      "science\t\t10\n",
      "jokes\t\t9\n",
      "thank-yous\t\t9\n",
      "gossip\t\t8\n",
      "international\t\t7\n",
      "police_scanner\t\t7\n",
      "rescue\t\t7\n",
      "psychic_readings\t\t6\n",
      "crime\t\t6\n",
      "special_events\t\t6\n",
      "birthday\t\t6\n",
      "classified_ads\t\t5\n",
      "horoscopes\t\t5\n",
      "sports\t\t5\n",
      "holiday\t\t5\n",
      "celebrity\t\t4\n",
      "flamenco\t\t3\n",
      "alternative\t\t3\n",
      "electronic\t\t3\n",
      "schoolhouse\t\t3\n",
      "web_sites\t\t3\n",
      "reality\t\t3\n",
      "pop_&_rock\t\t1\n",
      "world_music\t\t1\n",
      "latin\t\t1\n",
      "hip_hop/rap\t\t1\n",
      "technology\t\t1\n"
     ]
    }
   ],
   "source": [
    "#print counts for each genre from metadata file\n",
    "\n",
    "if not genre_map:\n",
    "    for g in sorted(genre_cts, key=genre_cts.get, reverse=True):\n",
    "        print('%s\\t\\t%d' % (g, genre_cts[g]))\n",
    "    \n",
    "#which genres are likely to be the most distinct? \n",
    "#we can do statistical analysis after feature extraction is done to find the most distinctive classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "polar-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_genres(genre_cts, min_examples=1000):\n",
    "    genre_map = {}\n",
    "    \n",
    "    #map subtypes to types with substrings\n",
    "    substrs = ['blues', 'punk', 'pop', 'rock', 'jazz', 'country', 'metal', 'techno',\n",
    "               'reggae', 'easy_listening', 'dance', 'house', 'trance', 'industrial', 'rap',  \n",
    "               'hip_hop', 'ambient', 'electronic', 'classical', 'children']\n",
    "    for g in genre_cts:\n",
    "        for substr in substrs:\n",
    "            if substr in g and g not in genre_map:\n",
    "                print('%s -> %s' % (g, substr))\n",
    "                genre_map[g] = substr\n",
    "            \n",
    "    #various other mappings\n",
    "    \n",
    "    map_to = 'metal'\n",
    "    for g in genre_cts:\n",
    "        if 'core' in g and g not in genre_map:\n",
    "            print('%s -> %s' % (g, map_to))\n",
    "            genre_map[g] = map_to\n",
    "            \n",
    "    map_to = 'bluegrass'\n",
    "    for g in genre_cts:\n",
    "        if 'grass' in g and g not in genre_map:\n",
    "            print('%s -> %s' % (g, map_to))\n",
    "            genre_map[g] = map_to\n",
    "            \n",
    "            \n",
    "    #direct mappings        \n",
    "    map_to = 'rock'\n",
    "    for g in ['indie', 'alternative_general', 'grunge', 'psychedelic', 'acid', 'ska', 'garage', 'glam']:\n",
    "        if g not in genre_map:\n",
    "            print('%s -> %s' % (g, map_to))\n",
    "            genre_map[g] = map_to\n",
    "    #overwrite some\n",
    "    del genre_map['rock-n-roll_oldies']\n",
    "    del genre_map['soft_rock']    \n",
    "    del genre_map['goth_rock']\n",
    "    del genre_map['rockabilly']\n",
    "    \n",
    "    map_to = 'oldies'\n",
    "    for g in ['soft_rock', 'adult_contemporary', 'swing/big_band', 'love_songs', 'lounge', \n",
    "              'aaa/adult_alternative', 'oldies', 'standards', 'crooners/vocals', 'romantic', \n",
    "              'rockabilly', 'rock-n-roll_oldies']:\n",
    "        if g not in genre_map:\n",
    "            print('%s -> %s' % (g, map_to))\n",
    "            genre_map[g] = map_to\n",
    "    \n",
    "    map_to = 'gospel'\n",
    "    for g in ['gospel', 'spiritual']:\n",
    "        if g not in genre_map:\n",
    "            print('%s -> %s' % (g, map_to))\n",
    "            genre_map[g] = map_to\n",
    "            \n",
    "    map_to = 'pop'\n",
    "    for g in ['contemporary_urban', 'contemporary', 'crossover', 'alternative_cover_songs']:\n",
    "        if g not in genre_map:\n",
    "            print('%s -> %s' % (g, map_to))\n",
    "            genre_map[g] = map_to\n",
    "            \n",
    "    map_to = 'ambient'\n",
    "    for g in ['mood_music', 'new_age']:\n",
    "        if g not in genre_map:\n",
    "            print('%s -> %s' % (g, map_to))\n",
    "            genre_map[g] = map_to\n",
    "    \n",
    "    map_to = 'classical'\n",
    "    for g in ['choral', 'chamber_music', 'baroque', 'medieval', 'renaissance', 'symphonic', 'opera', \n",
    "              'vocal', 'ensemble', 'piano', 'guitar', 'solo_instruments', 'woodwinds', 'strings']:\n",
    "        if g not in genre_map:\n",
    "            print('%s -> %s' % (g, map_to))\n",
    "            genre_map[g] = map_to\n",
    "            \n",
    "    map_to = 'jazz'\n",
    "    for g in ['world_fusion', 'soul', 'detroit', 'bebop', 'mod']:\n",
    "        if g not in genre_map:\n",
    "            print('%s -> %s' % (g, map_to))\n",
    "            genre_map[g] = map_to\n",
    "            \n",
    "    map_to = 'experimental'\n",
    "    for g in ['minimal', 'minimalist', 'experimental', 'noise', 'abstract']:\n",
    "        if g not in genre_map:\n",
    "            print('%s -> %s' % (g, map_to))\n",
    "            genre_map[g] = map_to\n",
    "            \n",
    "    map_to = 'funk'\n",
    "    for g in ['funk', 'funky_breaks', 'groove']:\n",
    "        if g not in genre_map:\n",
    "            print('%s -> %s' % (g, map_to))\n",
    "            genre_map[g] = map_to\n",
    "            \n",
    "    map_to = 'goth'\n",
    "    for g in ['goth_rock', 'darkwave', 'emo', 'goth']:\n",
    "        if g not in genre_map:\n",
    "            print('%s -> %s' % (g, map_to))\n",
    "            genre_map[g] = map_to\n",
    "            \n",
    "    map_to = 'hip_hop'\n",
    "    for g in ['trip_hop', 'west_coast', 'east_coast']:\n",
    "        if g not in genre_map:\n",
    "            print('%s -> %s' % (g, map_to))\n",
    "            genre_map[g] = map_to\n",
    "            \n",
    "    map_to = 'rap'\n",
    "    for g in ['new_school', 'old_school']:\n",
    "        if g not in genre_map:\n",
    "            print('%s -> %s' % (g, map_to))\n",
    "            genre_map[g] = map_to\n",
    "    \n",
    "    #just lumping these together\n",
    "    map_to = 'world'\n",
    "    for g in ['world/folk_cover_songs', 'general_latin', 'asian', 'americana', 'world_traditions', \n",
    "              'celtic', 'native_american', 'tribal', 'salsa', 'caribbean', 'african', 'brazilian', \n",
    "              'russian', 'indian', 'jewish/israeli', 'french', 'nouveau_flamenco', 'cuban', 'arabic',\n",
    "              'merengue', 'tropical', 'scandinavian', 'bossa_nova', 'european', 'south/central_american', \n",
    "              'traditional', 'quebecois', 'jungle']:\n",
    "        if g not in genre_map:\n",
    "            print('%s -> %s' % (g, map_to))\n",
    "            genre_map[g] = map_to\n",
    "            \n",
    "    #map types of spoken word\n",
    "    map_to = 'spoken_word'\n",
    "    for g in ['humor', 'self-help', 'stories_and_myths', 'audio_books', 'parodies', 'general_comedy', \n",
    "          'political_humor', 'interviews', 'satire', 'poetry', 'spoken_word', 'politics',\n",
    "         'speak_your_mind', 'paranormal', 'aliens', 'bodily_functions', 'shout_outs', 'witchcraft', \n",
    "         'horror_stories', 'commercials', 'mental_health', 'spoofs', 'recorded_greetings', \n",
    "         'lies', 'movies', 'opinions', 'education', 'emergency!', 'nonfiction', \n",
    "         'hypnosis', 'advice', 'radio', 'time_capsule_recordings', 'dumb_stories', 'love']:\n",
    "        if g not in genre_map:\n",
    "            print('%s -> %s' % (g, map_to))\n",
    "            genre_map[g] = map_to\n",
    "            \n",
    "            \n",
    "    #add remaining if there are enough instances\n",
    "    for g,c in genre_cts.items():\n",
    "        if g not in genre_map and c>min_examples:\n",
    "            print('%s -> %s' % (g, g))\n",
    "            genre_map[g] = g\n",
    "            \n",
    "    return genre_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "objective-simpson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "techno -> techno\n",
      "power_metal -> metal\n",
      "house -> house\n",
      "rock -> rock\n",
      "classical_general -> classical\n",
      "industrial -> industrial\n",
      "progressive_trance -> trance\n",
      "electronica -> electronic\n",
      "dance -> dance\n",
      "punk -> punk\n",
      "pop -> pop\n",
      "hip_hop -> hip_hop\n",
      "intelligent_techno -> techno\n",
      "hard_trance -> trance\n",
      "heavy_metal -> metal\n",
      "jump_blues -> blues\n",
      "progressive_metal -> metal\n",
      "rhythm_&_blues -> blues\n",
      "symphonic_electronica -> electronic\n",
      "goth_rock -> rock\n",
      "hard_house -> house\n",
      "trance -> trance\n",
      "reggae -> reggae\n",
      "industrial_rock -> rock\n",
      "death_metal -> metal\n",
      "power_pop -> pop\n",
      "general_jazz -> jazz\n",
      "ambient -> ambient\n",
      "guitar_rock -> rock\n",
      "instrumental_rock -> rock\n",
      "alternative_metal -> metal\n",
      "blues_vocals -> blues\n",
      "general_blues -> blues\n",
      "hardcore_punk -> punk\n",
      "rap -> rap\n",
      "folk_punk -> punk\n",
      "experimental/post_rock -> rock\n",
      "black_metal -> metal\n",
      "folk_rock -> rock\n",
      "acoustic_blues -> blues\n",
      "rockabilly -> rock\n",
      "alternative_country -> country\n",
      "christian_pop -> pop\n",
      "country_general -> country\n",
      "thrash/speed_metal -> metal\n",
      "jazz_vocals -> jazz\n",
      "skate_punk -> punk\n",
      "industrial_metal -> metal\n",
      "pop_vocals -> pop\n",
      "christian_country -> country\n",
      "electric_blues -> blues\n",
      "indie_pop/lo_fi -> pop\n",
      "acid_jazz -> jazz\n",
      "metalcore -> metal\n",
      "spiritual_rap -> rap\n",
      "gothic_metal -> metal\n",
      "progressive_rock -> rock\n",
      "pop/balada -> pop\n",
      "christian_metal -> metal\n",
      "electronic_classical -> electronic\n",
      "alternative_hip_hop -> hip_hop\n",
      "melodic_trance -> trance\n",
      "country_blues -> blues\n",
      "progressive_electronica -> electronic\n",
      "dancehall_reggae -> reggae\n",
      "christian_rock -> rock\n",
      "dark_ambient/noise -> ambient\n",
      "pop_punk -> punk\n",
      "surf_rock -> rock\n",
      "jazz_fusion -> jazz\n",
      "spiritual_children's -> children\n",
      "soft_rock -> rock\n",
      "rapcore -> rap\n",
      "doom/stoner_metal -> metal\n",
      "spiritual_rock -> rock\n",
      "smooth_jazz -> jazz\n",
      "industrial_electronic -> industrial\n",
      "europop -> pop\n",
      "deep_house -> house\n",
      "new_country -> country\n",
      "instrumental_metal -> metal\n",
      "brit_pop -> pop\n",
      "euro_dance -> dance\n",
      "christian_blues -> blues\n",
      "spiritual_easy_listening -> easy_listening\n",
      "rock_en_espanol -> rock\n",
      "spiritual_country -> country\n",
      "blues_rock -> blues\n",
      "spiritual_pop -> pop\n",
      "ambient_drum_n'_bass -> ambient\n",
      "latin_house -> house\n",
      "roots_reggae -> reggae\n",
      "general_children's_music -> children\n",
      "psytrance -> trance\n",
      "christian_easy_listening -> easy_listening\n",
      "classic_rock -> rock\n",
      "rock-n-roll_oldies -> rock\n",
      "experimental_classical -> classical\n",
      "southern_rock -> rock\n",
      "latin_jazz -> jazz\n",
      "traditional_country -> country\n",
      "vocal_house -> house\n",
      "spiritual_blues -> blues\n",
      "surf_punk -> punk\n",
      "christian_rap -> rap\n",
      "dub_reggae -> reggae\n",
      "j-pop -> pop\n",
      "spiritual_metal -> metal\n",
      "pop_and_rock_cover_songs -> pop\n",
      "traditional_jazz -> jazz\n",
      "hard_dance -> dance\n",
      "country_cover_songs -> country\n",
      "nu-metal -> metal\n",
      "easy_listening_cover_songs -> easy_listening\n",
      "blues_cover_songs -> blues\n",
      "filtered/disco_house -> house\n",
      "metal_cover_songs -> metal\n",
      "electronic_cover_songs -> electronic\n",
      "children's_cover_songs -> children\n",
      "hardcore_rap -> rap\n",
      "electronic -> electronic\n",
      "hip_hop_cover_songs -> hip_hop\n",
      "schoolhouse -> house\n",
      "progressive_house -> house\n",
      "metal -> metal\n",
      "pop_&_rock -> pop\n",
      "hip_hop/rap -> rap\n",
      "technology -> techno\n",
      "grindcore -> metal\n",
      "horrorcore -> metal\n",
      "post_hardcore -> metal\n",
      "happy_hardcore -> metal\n",
      "bluegrass -> bluegrass\n",
      "new_grass -> bluegrass\n",
      "indie -> rock\n",
      "alternative_general -> rock\n",
      "grunge -> rock\n",
      "psychedelic -> rock\n",
      "acid -> rock\n",
      "ska -> rock\n",
      "garage -> rock\n",
      "glam -> rock\n",
      "soft_rock -> oldies\n",
      "adult_contemporary -> oldies\n",
      "swing/big_band -> oldies\n",
      "love_songs -> oldies\n",
      "lounge -> oldies\n",
      "aaa/adult_alternative -> oldies\n",
      "oldies -> oldies\n",
      "standards -> oldies\n",
      "crooners/vocals -> oldies\n",
      "romantic -> oldies\n",
      "rockabilly -> oldies\n",
      "rock-n-roll_oldies -> oldies\n",
      "gospel -> gospel\n",
      "spiritual -> gospel\n",
      "contemporary_urban -> pop\n",
      "contemporary -> pop\n",
      "crossover -> pop\n",
      "alternative_cover_songs -> pop\n",
      "mood_music -> ambient\n",
      "new_age -> ambient\n",
      "choral -> classical\n",
      "chamber_music -> classical\n",
      "baroque -> classical\n",
      "medieval -> classical\n",
      "renaissance -> classical\n",
      "symphonic -> classical\n",
      "opera -> classical\n",
      "vocal -> classical\n",
      "ensemble -> classical\n",
      "piano -> classical\n",
      "guitar -> classical\n",
      "solo_instruments -> classical\n",
      "woodwinds -> classical\n",
      "strings -> classical\n",
      "world_fusion -> jazz\n",
      "soul -> jazz\n",
      "detroit -> jazz\n",
      "bebop -> jazz\n",
      "mod -> jazz\n",
      "minimal -> experimental\n",
      "minimalist -> experimental\n",
      "experimental -> experimental\n",
      "noise -> experimental\n",
      "abstract -> experimental\n",
      "funk -> funk\n",
      "funky_breaks -> funk\n",
      "groove -> funk\n",
      "goth_rock -> goth\n",
      "darkwave -> goth\n",
      "emo -> goth\n",
      "goth -> goth\n",
      "trip_hop -> hip_hop\n",
      "west_coast -> hip_hop\n",
      "east_coast -> hip_hop\n",
      "new_school -> rap\n",
      "old_school -> rap\n",
      "world/folk_cover_songs -> world\n",
      "general_latin -> world\n",
      "asian -> world\n",
      "americana -> world\n",
      "world_traditions -> world\n",
      "celtic -> world\n",
      "native_american -> world\n",
      "tribal -> world\n",
      "salsa -> world\n",
      "caribbean -> world\n",
      "african -> world\n",
      "brazilian -> world\n",
      "russian -> world\n",
      "indian -> world\n",
      "jewish/israeli -> world\n",
      "french -> world\n",
      "nouveau_flamenco -> world\n",
      "cuban -> world\n",
      "arabic -> world\n",
      "merengue -> world\n",
      "tropical -> world\n",
      "scandinavian -> world\n",
      "bossa_nova -> world\n",
      "european -> world\n",
      "south/central_american -> world\n",
      "traditional -> world\n",
      "quebecois -> world\n",
      "jungle -> world\n",
      "humor -> spoken_word\n",
      "self-help -> spoken_word\n",
      "stories_and_myths -> spoken_word\n",
      "audio_books -> spoken_word\n",
      "parodies -> spoken_word\n",
      "general_comedy -> spoken_word\n",
      "political_humor -> spoken_word\n",
      "interviews -> spoken_word\n",
      "satire -> spoken_word\n",
      "poetry -> spoken_word\n",
      "spoken_word -> spoken_word\n",
      "politics -> spoken_word\n",
      "speak_your_mind -> spoken_word\n",
      "paranormal -> spoken_word\n",
      "aliens -> spoken_word\n",
      "bodily_functions -> spoken_word\n",
      "shout_outs -> spoken_word\n",
      "witchcraft -> spoken_word\n",
      "horror_stories -> spoken_word\n",
      "commercials -> spoken_word\n",
      "mental_health -> spoken_word\n",
      "spoofs -> spoken_word\n",
      "recorded_greetings -> spoken_word\n",
      "lies -> spoken_word\n",
      "movies -> spoken_word\n",
      "opinions -> spoken_word\n",
      "education -> spoken_word\n",
      "emergency! -> spoken_word\n",
      "nonfiction -> spoken_word\n",
      "hypnosis -> spoken_word\n",
      "advice -> spoken_word\n",
      "radio -> spoken_word\n",
      "time_capsule_recordings -> spoken_word\n",
      "dumb_stories -> spoken_word\n",
      "love -> spoken_word\n",
      "club -> club\n",
      "breakbeat/breaks -> breakbeat/breaks\n",
      "tech_step -> tech_step\n",
      "drum_n'_bass -> drum_n'_bass\n",
      "new_wave -> new_wave\n",
      "acoustic -> acoustic\n",
      "down_tempo -> down_tempo\n",
      "folk -> folk\n",
      "film_music -> film_music\n",
      "freestyles -> freestyles\n",
      "game_soundtracks -> game_soundtracks\n",
      "leftfield -> leftfield\n",
      "goa -> goa\n",
      "beats -> beats\n",
      "dirty_south -> dirty_south\n",
      "big_beat -> big_beat\n"
     ]
    }
   ],
   "source": [
    "if not genre_map:\n",
    "    genre_map = map_genres(genre_cts, min_examples=1000)\n",
    "    write_genre_map(genre_map, genre_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add metadata from files to data dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "inside-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_extracted_metadata_and_size(data, mp3s_path, genre_map, metadata_path):\n",
    "    ttl = 0\n",
    "    extracted_genres = 0\n",
    "    genre_match = 0\n",
    "    over_5mb = 0\n",
    "    \n",
    "    for i, fn in enumerate(data.keys()):\n",
    "        if i%10000==0:\n",
    "            print('Total: %d\\tExtracted genre count: %d\\tMatching genres: %d\\t> 5 Mb: %d' % (\n",
    "                ttl, extracted_genres, genre_match, over_5mb))\n",
    "            with gzip.open(metadata_path, 'wt', encoding='utf-8') as oz:\n",
    "                json.dump(data, oz)\n",
    "                \n",
    "        fp = '%s/%s' % (mp3s_path, fn)\n",
    "        if not os.path.exists(fp):\n",
    "            continue\n",
    "            \n",
    "        ttl+=1\n",
    "            \n",
    "        data[fn]['mb'] = os.path.getsize(fp)/1024**2\n",
    "        if data[fn]['mb'] > 5:\n",
    "            over_5mb+=1\n",
    "        \n",
    "        #metadata = {'encoder': 'LAME3.92 ', 'title': 'Believe', 'artist': 'DREAMTRONIX', \n",
    "        #            'comment': 'http://www.mp3.com/DREAMTRONIX','genre': 'Blues'}\n",
    "        metadata = mediainfo(fp).get('TAG', None)\n",
    "        if metadata==None:\n",
    "            continue\n",
    "            \n",
    "        if 'genre' in metadata:\n",
    "            extracted_genres += 1\n",
    "            \n",
    "            meta_genre = format_text(metadata['genre'])\n",
    "            data[fn]['mp3_metadata_genre'] = meta_genre\n",
    "            \n",
    "            orig_genre = data[fn]['genre']\n",
    "            \n",
    "            meta_genre = genre_map.get(meta_genre, meta_genre)\n",
    "            orig_genre = genre_map.get(orig_genre, orig_genre)\n",
    "            \n",
    "            if meta_genre==orig_genre:\n",
    "                data[fn]['genre_match'] = True\n",
    "                genre_match += 1\n",
    "        if 'artist' in metadata:\n",
    "            data[fn]['mp3_metadata_artist'] = format_text(metadata['artist'])\n",
    "        if 'encoder' in metadata:\n",
    "            data[fn]['mp3_metadata_encoder'] = metadata['encoder'].lower()\n",
    "\n",
    "    print('Total: %d\\tExtracted genre count: %d\\tMatching genres: %d\\t> 5 Mb: %d' % (\n",
    "        ttl, extracted_genres, genre_match, over_5mb))\n",
    "    with gzip.open(metadata_path, 'wt', encoding='utf-8') as oz:\n",
    "        json.dump(data, oz)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-juice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 0\tExtracted genre count: 0\tMatching genres: 0\t> 5 Mb: 0\n",
      "Total: 4631\tExtracted genre count: 4510\tMatching genres: 100\t> 5 Mb: 743\n",
      "Total: 9254\tExtracted genre count: 9015\tMatching genres: 219\t> 5 Mb: 1476\n",
      "Total: 13862\tExtracted genre count: 13498\tMatching genres: 347\t> 5 Mb: 2293\n",
      "Total: 18431\tExtracted genre count: 17942\tMatching genres: 447\t> 5 Mb: 3085\n",
      "Total: 22951\tExtracted genre count: 22378\tMatching genres: 559\t> 5 Mb: 3820\n",
      "Total: 27471\tExtracted genre count: 26785\tMatching genres: 666\t> 5 Mb: 4539\n",
      "Total: 32024\tExtracted genre count: 31240\tMatching genres: 755\t> 5 Mb: 5247\n"
     ]
    }
   ],
   "source": [
    "data = add_extracted_metadata_and_size(data, mp3s_path, genre_map, metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Get some samples from each genre\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_genres = set(['sound_effects', 'spoken_word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "quality-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_examples(data, mp3s_path, local_mp3s_path, genre_map, excluded_genres, num_per_genre, max_mb=5):\n",
    "    ttl=0\n",
    "    \n",
    "    genre_num = {g:0 for g in set(genre_map.values())}\n",
    "    \n",
    "    for genre in os.listdir(local_mp3s_path):\n",
    "        genre_path = '%s/%s' % (local_mp3s_path, genre)\n",
    "        for fn in os.listdir(genre_path):\n",
    "            genre_num[genre] += 1\n",
    "            \n",
    "    fns = list(data.keys())\n",
    "    random.shuffle(fns)\n",
    "        \n",
    "    for fn in fns:\n",
    "        meta = data[fn]\n",
    "        if meta['genre'] not in genre_map:\n",
    "            continue\n",
    "        if meta['mb'] > max_mb:\n",
    "            continue\n",
    "            \n",
    "        genre = genre_map[meta['genre']]\n",
    "        \n",
    "        if genre in excluded_genres:\n",
    "            continue\n",
    "            \n",
    "        if genre_num[genre]>=num_per_genre:\n",
    "            continue\n",
    "            \n",
    "        genre_path = '%s/%s' % (local_mp3s_path, genre)\n",
    "        if not os.path.exists(genre_path):\n",
    "            print(genre)\n",
    "            os.mkdir(genre_path)\n",
    "            \n",
    "        in_path = '%s/%s' % (mp3s_path, fn)\n",
    "        if not os.path.exists(in_path):\n",
    "            continue\n",
    "            \n",
    "        out_path = '%s/%s' % (genre_path, fn)\n",
    "        #already downloaded\n",
    "        if os.path.exists(out_path):\n",
    "            continue\n",
    "        \n",
    "        genre_num[genre]+=1\n",
    "        shutil.copy(in_path, out_path)\n",
    "        ttl+=1\n",
    "        \n",
    "        if ttl%100==0:\n",
    "            print(ttl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "sustainable-banking",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dance\n",
      "rock\n",
      "hip_hop\n",
      "metal\n",
      "pop\n",
      "rap\n",
      "experimental\n",
      "jazz\n",
      "punk\n",
      "extreme_metal\n",
      "blues\n",
      "country\n",
      "industrial\n",
      "goth\n",
      "soft_rock\n",
      "acoustic\n",
      "ambient\n",
      "folk\n",
      "world\n",
      "childrens\n",
      "soundtrack\n",
      "old_rock\n",
      "reggae\n",
      "100\n",
      "classical\n",
      "instrumental\n",
      "vocals\n",
      "funk\n",
      "200\n",
      "holiday\n",
      "300\n",
      "spiritual\n",
      "bluegrass\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "vocal\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "musicals\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n"
     ]
    }
   ],
   "source": [
    "num_per_genre = 100\n",
    "get_examples(data, mp3s_path, local_mp3s_path, genre_map, excluded_genres, num_per_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-potato",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-drilling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-representation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
