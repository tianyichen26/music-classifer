{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "equipped-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, gzip, json, pickle, shutil, random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "liked-agriculture",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/tianyi/Northeastern University/Machine Learning Final Project - Music Classification - Documents'\n",
    "myspace_mp3s_path = '%s/myspace_mp3s' % data_path\n",
    "metadata_path = '%s/metadata.json.gz' % myspace_mp3s_path\n",
    "genre_map_path = '%s/genre_map.pkl' % myspace_mp3s_path\n",
    "mfcc_path = '%s/audio_features/mfcc' % data_path\n",
    "\n",
    "#'rock', 'metal', 'dance', 'rap', 'pop', 'jazz', 'experimental', 'world', 'electronic', 'folk', 'punk', 'blues'\n",
    "binary_genres = ['metal', 'classical']\n",
    "\n",
    "lab_idx = {g:i for i,g in enumerate(binary_genres)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "successful-criterion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock 13158\n",
      "metal 8782\n",
      "alternative 8778\n",
      "rap 5906\n",
      "dance 5624\n",
      "pop 4684\n",
      "jazz 4552\n",
      "hip_hop 4526\n",
      "experimental 3686\n",
      "other 3544\n",
      "world 2225\n",
      "electronic 2127\n",
      "folk 1804\n",
      "punk 1729\n",
      "blues 1472\n",
      "ambient 1299\n",
      "reggae 1114\n",
      "goth 722\n",
      "acoustic 678\n",
      "country 533\n",
      "house 512\n",
      "classical 486\n",
      "spiritual 369\n",
      "oldies 248\n",
      "progressive 221\n",
      "funk 142\n",
      "easy_listening 131\n",
      "spoken_word 130\n",
      "bluegrass 48\n",
      "industrial 44\n",
      "showtunes 38\n",
      "disco 23\n"
     ]
    }
   ],
   "source": [
    "genre_cts = {}\n",
    "for genre in os.listdir(mfcc_path):\n",
    "    genre_path = '%s/%s' % (mfcc_path, genre)\n",
    "    genre_cts[genre] = len(os.listdir(genre_path))\n",
    "    \n",
    "min_recs = min([genre_cts[g] for g in binary_genres])   \n",
    "\n",
    "for g in sorted(genre_cts, key=genre_cts.get, reverse=True):\n",
    "    print(g, genre_cts[g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "organized-relative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('46/std_1f69563352d19cb0132334cd0d3adeaf.mp3',\n",
       " {'song_name': 'big_yellow_moon',\n",
       "  'artist_name': 'bill_nelson',\n",
       "  'mp3_zipname': '46',\n",
       "  'mp3_filename': 'std_1f69563352d19cb0132334cd0d3adeaf.mp3',\n",
       "  'genres': ['rock', 'electronica', 'alternative']})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open(metadata_path, 'rt', encoding='utf-8') as fz:\n",
    "    metadata = json.load(fz)\n",
    "\n",
    "with open(genre_map_path, 'rb') as f:\n",
    "    genre_map = pickle.load(f)\n",
    "    \n",
    "#example metadata\n",
    "kys = list(metadata.keys())\n",
    "ky=kys[0]\n",
    "ky, metadata[ky]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "scenic-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc_lengths(mfcc_path, genres, max_recs):\n",
    "    lens=[]\n",
    "    \n",
    "    for genre in binary_genres:\n",
    "        genre_path = '%s/%s' % (mfcc_path, genre)\n",
    "        ct = 0\n",
    "        for fn in os.listdir(genre_path):\n",
    "            fp = '%s/%s' % (genre_path, fn)\n",
    "            mfcc = np.load(fp)\n",
    "            lens.append(mfcc.shape[1])\n",
    "            ct+=1\n",
    "            if ct>=min_recs:\n",
    "                break\n",
    "                \n",
    "    l = np.array(lens)\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "robust-subject",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean mfcc length: 9853.0833, std: 4784.7813\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = get_mfcc_lengths(mfcc_path, binary_genres, min_recs)\n",
    "\n",
    "print('Mean mfcc length: %.4f, std: %.4f' % (l.mean(), l.std())) #9792.02380952381, 4837.91379828136\n",
    "\n",
    "plt.hist(l, bins=100, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-laugh",
   "metadata": {},
   "source": [
    "### Try different ways of dealing with the varying mfcc lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "successful-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc = np.load('%s/acoustic/msp_1_std_1b7ee19baed6ae4ea7332a60db0bcb4f.npy' % mfcc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "clean-amount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.8108591e+02,  1.2224055e+02,  2.8064362e+01,  3.1553217e+01,\n",
       "         1.5940080e+01,  1.3792233e+01,  4.4775543e+00,  5.4401940e-01,\n",
       "        -8.0222225e+00, -9.0548048e+00, -7.3031354e+00, -8.1062689e+00,\n",
       "        -9.4938993e+00, -7.5461569e+00, -9.5483360e+00, -1.1156130e+01,\n",
       "        -1.2253296e+01, -7.0494881e+00, -7.5009913e+00, -6.9211936e+00],\n",
       "       [ 8.6951828e+01,  2.9867422e+01,  1.9666704e+01,  1.4971158e+01,\n",
       "         1.1757245e+01,  8.2338200e+00,  8.2472515e+00,  7.4393983e+00,\n",
       "         7.9877319e+00,  1.0237029e+01,  8.3215666e+00,  7.6278958e+00,\n",
       "         8.1165676e+00,  7.5231209e+00,  7.4042001e+00,  6.7408314e+00,\n",
       "         6.5452747e+00,  6.6313405e+00,  7.7863317e+00,  7.5268083e+00],\n",
       "       [-2.0438838e-01,  1.9405127e+00,  8.4137917e-01,  7.3870349e-01,\n",
       "         7.7184796e-01,  5.1357436e-01,  1.5301127e+00,  9.4353080e-01,\n",
       "         3.4467864e-01,  2.7901173e-02, -4.7985554e-02, -1.4419651e-01,\n",
       "         7.4904442e-02, -1.5321231e-01,  2.5043797e-01,  5.4659796e-01,\n",
       "         2.1384959e+00,  1.0369496e+00,  5.6265497e-01,  5.4365230e-01],\n",
       "       [ 7.2641796e-01, -1.0781850e+00, -7.8138596e-01,  4.7336259e-01,\n",
       "        -7.4200726e-01, -7.6374947e-03, -8.4771901e-01, -1.3314392e-01,\n",
       "        -2.1730286e-01,  1.8870550e-01,  1.2844105e-01,  1.4315043e-01,\n",
       "         6.3976988e-02,  2.5204366e-02, -1.0298510e-01,  7.9656824e-02,\n",
       "         4.8126605e-01,  2.8682962e-01, -1.4631346e-01,  2.4007763e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([mfcc.mean(axis=1), mfcc.std(axis=1), stats.kurtosis(mfcc, axis=1), stats.skew(mfcc, axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "optical-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(x, y):\n",
    "    idx = np.arange(x.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "def normalize_data(x):\n",
    "    return (x-x.mean())/x.std()\n",
    "\n",
    "\n",
    "def get_col_stats(mfcc_path, genres, lab_idx, max_recs):\n",
    "    mfccs = []\n",
    "    y=[]\n",
    "    \n",
    "    for genre in genres:\n",
    "        genre_path = '%s/%s' % (mfcc_path, genre)\n",
    "        ct = 0\n",
    "        \n",
    "        for fn in os.listdir(genre_path):\n",
    "            fp = '%s/%s' % (genre_path, fn)\n",
    "            \n",
    "            mfcc = np.load(fp)\n",
    "            mfccs.append(np.hstack([mfcc.mean(axis=1), \n",
    "                                    mfcc.std(axis=1), \n",
    "                                    stats.kurtosis(mfcc, axis=1), \n",
    "                                    stats.skew(mfcc, axis=1)]))\n",
    "            \n",
    "            y.append(lab_idx[genre])\n",
    "            \n",
    "            ct+=1\n",
    "            if ct>=max_recs:\n",
    "                break\n",
    "                \n",
    "    x = np.array(mfccs)\n",
    "    x = normalize_data(x)\n",
    "    \n",
    "    y = np.array(y)\n",
    "    \n",
    "    return shuffle_data(x, y)\n",
    "\n",
    "                \n",
    "def truncate_cols(mfcc_path, genres, lab_idx, col_len, max_recs):\n",
    "    mfccs = []\n",
    "    y=[]\n",
    "    \n",
    "    for genre in genres:\n",
    "        genre_path = '%s/%s' % (mfcc_path, genre)\n",
    "        ct = 0\n",
    "        \n",
    "        for fn in os.listdir(genre_path):\n",
    "            fp = '%s/%s' % (genre_path, fn)\n",
    "            \n",
    "            mfcc = np.load(fp)[:,:col_len]\n",
    "            mfccs.append(np.pad(mfcc, ((0,0),(0,col_len-mfcc.shape[1])), 'constant'))\n",
    "            \n",
    "            y.append(lab_idx[genre])\n",
    "            \n",
    "            ct+=1\n",
    "            if ct>=max_recs:\n",
    "                break\n",
    "                \n",
    "    x = np.array(mfccs)\n",
    "    y = np.array(y)\n",
    "                \n",
    "    return shuffle_data(x, y)\n",
    "\n",
    "\n",
    "def svd_reduce(x, n_components=100):\n",
    "    svd = TruncatedSVD(n_components=n_components)\n",
    "    x = svd.fit_transform(x.reshape(x.shape[0], -1))\n",
    "    print(x.shape, svd.explained_variance_ratio_.sum())\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "global-quarter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((972, 80), (972,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = get_col_stats(mfcc_path, binary_genres, lab_idx, min_recs)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "spanish-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test = x.shape[0]//5\n",
    "x_train, x_test, y_train, y_test = x[num_test:], x[:num_test], y[num_test:], y[:num_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-vacation",
   "metadata": {},
   "source": [
    "### Different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-passenger",
   "metadata": {},
   "source": [
    "#### Col_stats, Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "younger-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "atmospheric-cutting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92        86\n",
      "           1       0.96      0.90      0.93       108\n",
      "\n",
      "    accuracy                           0.92       194\n",
      "   macro avg       0.92      0.93      0.92       194\n",
      "weighted avg       0.93      0.92      0.92       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(C=1.0, max_iter=1000)\n",
    "\n",
    "clf = log_reg.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "#0.91"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-patent",
   "metadata": {},
   "source": [
    "#### Col_stats, LinearSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "robust-alaska",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91        86\n",
      "           1       0.96      0.89      0.92       108\n",
      "\n",
      "    accuracy                           0.92       194\n",
      "   macro avg       0.92      0.92      0.92       194\n",
      "weighted avg       0.92      0.92      0.92       194\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tianyi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lin_svm = LinearSVC(C=1.0, loss='hinge', max_iter=10000)\n",
    "\n",
    "clf = lin_svm.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "#0.92"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-powder",
   "metadata": {},
   "source": [
    "#### Col_stats, SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "alive-riding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74        86\n",
      "           1       0.79      0.79      0.79       108\n",
      "\n",
      "    accuracy                           0.77       194\n",
      "   macro avg       0.77      0.77      0.77       194\n",
      "weighted avg       0.77      0.77      0.77       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(C=1.0, kernel='sigmoid', gamma='scale')\n",
    "\n",
    "clf = svm.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#poly, degree 2: 0.89\n",
    "#poly, degree 3: 0.88\n",
    "#rbf: 0.9\n",
    "#sigmoid: 0.83"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-trace",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "prepared-appreciation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       101\n",
      "           1       0.90      0.88      0.89        93\n",
      "\n",
      "    accuracy                           0.90       194\n",
      "   macro avg       0.90      0.90      0.90       194\n",
      "weighted avg       0.90      0.90      0.90       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(10), solver='adam', max_iter=2500)\n",
    "\n",
    "clf = mlp.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#adam\n",
    "#hid 3 : 0.91\n",
    "#hid 5 : 0.92\n",
    "#hid 10 : 0.92\n",
    "#hid 20 : 0.91\n",
    "#hid 50 : 0.91\n",
    "#hid 100 : 0.91\n",
    "#hid 200 : 0.91\n",
    "#hid 500 : 0.90\n",
    "#hid 5,5 : 0.88\n",
    "#hid 10,5 : 0.89\n",
    "#hid 20,10 : 0.9\n",
    "#hid 100,50 : 0.89\n",
    "\n",
    "#sgd always did a bit worse than adam, lbfgs did even worse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-endorsement",
   "metadata": {},
   "source": [
    "####  = QuadraticDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "improved-drilling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.89       101\n",
      "           1       0.85      0.92      0.89        93\n",
      "\n",
      "    accuracy                           0.89       194\n",
      "   macro avg       0.89      0.89      0.89       194\n",
      "weighted avg       0.89      0.89      0.89       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "    \n",
    "clf = qda.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "#0.87"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-harvard",
   "metadata": {},
   "source": [
    "#### Custom network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "confident-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicClassifier(nn.Module):\n",
    "    def __init__(self, num_in, num_out):\n",
    "        super(MusicClassifier, self).__init__()\n",
    "        self.layer_1 = nn.Linear(num_in, 256)\n",
    "        self.layer_2 = nn.Linear(256, 256)\n",
    "        self.layer_out = nn.Linear(256, num_out)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(256)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(256)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer_1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "blond-output",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = MusicClassifier(x_train.shape[1], 1)\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "coordinate-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x, y, model, optimizer, criterion, batch_size, epochs, device):\n",
    "    x_batches = [x[i*batch_size:(i+1)*batch_size] for i in range((x.shape[0]//batch_size) + 1)]\n",
    "    y_batches = [y[i*batch_size:(i+1)*batch_size] for i in range((x.shape[0]//batch_size) + 1)]\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        \n",
    "        idx = list(range(len(x_batches)))\n",
    "        random.shuffle(idx)\n",
    "        x_batches = [x_batches[i] for i in idx]\n",
    "        y_batches = [y_batches[i] for i in idx]\n",
    "        \n",
    "        for x_batch, y_batch in zip(x_batches, y_batches):\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(x_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "        print('Epoch %d\\tLoss: %.8f\\tAcc: %.8f' % (epoch, epoch_loss/len(x_batches), epoch_acc/len(x_batches)))\n",
    "        \n",
    "    return model\n",
    "        \n",
    "        \n",
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    cor = (y_pred == y_test).sum().float()\n",
    "    acc = cor/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "\n",
    "def test(x_test, y_test, model):\n",
    "    model.eval()\n",
    "    y_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x_test)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        y_pred = torch.round(y_pred).cpu().numpy()\n",
    "        y_preds.append(y_pred)\n",
    "\n",
    "    y_preds = [a.squeeze().tolist() for a in y_preds]\n",
    "    y_preds = [int(y) for y in y_preds[0]]\n",
    "    \n",
    "    print(classification_report(y_test.tolist(), y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "spiritual-philadelphia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\tLoss: 0.35129818\tAcc: 84.00000000\n",
      "Epoch 2\tLoss: 0.23824837\tAcc: 91.62500000\n",
      "Epoch 3\tLoss: 0.20600965\tAcc: 91.75000000\n",
      "Epoch 4\tLoss: 0.18998510\tAcc: 92.25000000\n",
      "Epoch 5\tLoss: 0.17556997\tAcc: 92.62500000\n",
      "Epoch 6\tLoss: 0.16100627\tAcc: 94.00000000\n",
      "Epoch 7\tLoss: 0.15209224\tAcc: 94.25000000\n",
      "Epoch 8\tLoss: 0.14115577\tAcc: 94.37500000\n",
      "Epoch 9\tLoss: 0.12593920\tAcc: 95.00000000\n",
      "Epoch 10\tLoss: 0.11604617\tAcc: 95.62500000\n",
      "Epoch 11\tLoss: 0.10517112\tAcc: 96.12500000\n",
      "Epoch 12\tLoss: 0.09229265\tAcc: 96.75000000\n",
      "Epoch 13\tLoss: 0.08453739\tAcc: 97.12500000\n",
      "Epoch 14\tLoss: 0.07822492\tAcc: 97.37500000\n",
      "Epoch 15\tLoss: 0.06613373\tAcc: 98.00000000\n",
      "Epoch 16\tLoss: 0.05647346\tAcc: 98.12500000\n",
      "Epoch 17\tLoss: 0.04368902\tAcc: 99.12500000\n",
      "Epoch 18\tLoss: 0.03834940\tAcc: 99.12500000\n",
      "Epoch 19\tLoss: 0.03124489\tAcc: 99.50000000\n",
      "Epoch 20\tLoss: 0.02834616\tAcc: 99.25000000\n",
      "Epoch 21\tLoss: 0.02659929\tAcc: 99.37500000\n",
      "Epoch 22\tLoss: 0.02364095\tAcc: 99.50000000\n",
      "Epoch 23\tLoss: 0.01670141\tAcc: 100.00000000\n",
      "Epoch 24\tLoss: 0.01393410\tAcc: 99.75000000\n",
      "Epoch 25\tLoss: 0.01257343\tAcc: 100.00000000\n",
      "Epoch 26\tLoss: 0.00923845\tAcc: 100.00000000\n",
      "Epoch 27\tLoss: 0.00665415\tAcc: 100.00000000\n",
      "Epoch 28\tLoss: 0.00588291\tAcc: 100.00000000\n",
      "Epoch 29\tLoss: 0.00482057\tAcc: 100.00000000\n",
      "Epoch 30\tLoss: 0.00393489\tAcc: 100.00000000\n",
      "Epoch 31\tLoss: 0.00333474\tAcc: 100.00000000\n",
      "Epoch 32\tLoss: 0.00306856\tAcc: 100.00000000\n",
      "Epoch 33\tLoss: 0.00292989\tAcc: 100.00000000\n",
      "Epoch 34\tLoss: 0.00252575\tAcc: 100.00000000\n",
      "Epoch 35\tLoss: 0.00230210\tAcc: 100.00000000\n",
      "Epoch 36\tLoss: 0.00223598\tAcc: 100.00000000\n",
      "Epoch 37\tLoss: 0.00204330\tAcc: 100.00000000\n",
      "Epoch 38\tLoss: 0.00184718\tAcc: 100.00000000\n",
      "Epoch 39\tLoss: 0.00164816\tAcc: 100.00000000\n",
      "Epoch 40\tLoss: 0.00155406\tAcc: 100.00000000\n",
      "Epoch 41\tLoss: 0.00147037\tAcc: 100.00000000\n",
      "Epoch 42\tLoss: 0.00139604\tAcc: 100.00000000\n",
      "Epoch 43\tLoss: 0.00128802\tAcc: 100.00000000\n",
      "Epoch 44\tLoss: 0.00125955\tAcc: 100.00000000\n",
      "Epoch 45\tLoss: 0.00117207\tAcc: 100.00000000\n",
      "Epoch 46\tLoss: 0.00121962\tAcc: 100.00000000\n",
      "Epoch 47\tLoss: 0.00100268\tAcc: 100.00000000\n",
      "Epoch 48\tLoss: 0.00103652\tAcc: 100.00000000\n",
      "Epoch 49\tLoss: 0.00096362\tAcc: 100.00000000\n",
      "Epoch 50\tLoss: 0.00089411\tAcc: 100.00000000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "model = train_model(torch.from_numpy(x), torch.from_numpy(y).float(), \n",
    "            model, optimizer, criterion, batch_size, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "western-celebrity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       101\n",
      "         1.0       1.00      1.00      1.00        93\n",
      "\n",
      "    accuracy                           1.00       194\n",
      "   macro avg       1.00      1.00      1.00       194\n",
      "weighted avg       1.00      1.00      1.00       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(torch.from_numpy(x_test).to(device), torch.from_numpy(y_test).float().to(device), model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-settle",
   "metadata": {},
   "source": [
    "#### CNN for padded raw mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-comparative",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
